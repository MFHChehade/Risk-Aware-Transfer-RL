This GitHub project focuses on implementing a novel approach to Risk-Aware Transfer in Reinforcement Learning (RL). In traditional RL, models are trained to optimize for a specific task without considering potential risks during testing. However, this project introduces a unique perspective by incorporating risk at the test level rather than during training.
